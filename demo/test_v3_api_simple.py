"""V3 API ç®€å•æµ‹è¯• - å®ç°ä¸ extract_memory åŒæ¬¾åŠŸèƒ½

åŠŸèƒ½ï¼š
1. æ¸…ç©ºæ•°æ®åº“ï¼ˆMongoDBã€ESã€Milvusï¼‰
2. ä½¿ç”¨ V3 API æ–¹å¼æå–è®°å¿†
3. åŒ…å«ï¼šMemCell + è¯­ä¹‰è®°å¿† + Event Log
4. åŒæ­¥åˆ° Milvus/ES
"""

import asyncio
import json
from pathlib import Path
from typing import List, Dict, Any

from common_utils.datetime_utils import from_iso_format, get_now_with_timezone
from memory_layer.types import RawDataType
from memory_layer.memcell_extractor.base_memcell_extractor import RawData
from memory_layer.memory_manager import MemorizeRequest
from agentic_layer.memory_manager import MemoryManager
from core.di import get_bean_by_type
from infra_layer.adapters.out.persistence.repository.memcell_raw_repository import (
    MemCellRawRepository,
)
from infra_layer.adapters.out.search.repository.episodic_memory_milvus_repository import (
    EpisodicMemoryMilvusRepository,
)
from infra_layer.adapters.out.search.repository.episodic_memory_es_repository import (
    EpisodicMemoryEsRepository,
)


DATA_FILE = Path("/Users/admin/Documents/Projects/opensource/memsys-opensource/data/assistant_chat_zh.json")


async def clear_all_data():
    """æ¸…ç©º MongoDBã€ESã€Milvus çš„æ•°æ®"""
    print("=" * 80)
    print("æ¸…ç©ºæ•°æ®åº“")
    print("=" * 80)
    
    # 1. æ¸…ç©º MongoDB MemCell
    print("\n[MongoDB] æ¸…ç©º MemCell é›†åˆ...")
    memcell_repo = get_bean_by_type(MemCellRawRepository)
    from infra_layer.adapters.out.persistence.document.memory.memcell import MemCell
    deleted_count = await MemCell.delete_all()
    print(f"  âœ… å·²åˆ é™¤ {deleted_count.deleted_count if deleted_count else 0} æ¡ MemCell")
    
    # 2. æ¸…ç©º Milvusï¼ˆåˆ é™¤æ‰€æœ‰è®°å½•ï¼‰
    print("\n[Milvus] æ¸…ç©ºè®°å¿†é›†åˆ...")
    milvus_repo = get_bean_by_type(EpisodicMemoryMilvusRepository)
    # ä½¿ç”¨ collection.delete() åˆ é™¤æ‰€æœ‰è®°å½•ï¼ˆid != "" æ°¸è¿œä¸ºçœŸï¼‰
    delete_result = await milvus_repo.collection.delete(expr='id != ""')
    print(f"  âœ… å·²åˆ é™¤ {delete_result.delete_count} æ¡è®°å½•")
    await milvus_repo.flush()
    print(f"  âœ… Milvus å·²åˆ·æ–°")
    
    # 3. æ¸…ç©º ES
    print("\n[ES] æ¸…ç©ºç´¢å¼•...")
    es_repo = get_bean_by_type(EpisodicMemoryEsRepository)
    client = await es_repo.get_client()
    index_name = es_repo.get_index_name()
    
    # åˆ é™¤æ‰€æœ‰æ–‡æ¡£
    delete_response = await client.delete_by_query(
        index=index_name,
        body={"query": {"match_all": {}}}
    )
    print(f"  âœ… å·²åˆ é™¤ {delete_response.get('deleted', 0)} æ¡æ–‡æ¡£")
    
    # åˆ·æ–°ç´¢å¼•
    await client.indices.refresh(index=index_name)
    print(f"  âœ… ç´¢å¼•å·²åˆ·æ–°")
    
    print("\nâœ… æ‰€æœ‰æ•°æ®å·²æ¸…ç©º")


def load_chat_data(file_path: Path) -> List[Dict[str, Any]]:
    """åŠ è½½èŠå¤©æ•°æ®"""
    with file_path.open("r", encoding="utf-8") as f:
        data = json.load(f)
    
    if isinstance(data, dict):
        return data.get("conversation_list", [])
    return data


def normalize_message(entry: Dict[str, Any]) -> Dict[str, Any] | None:
    """å½’ä¸€åŒ–æ¶ˆæ¯æ ¼å¼"""
    timestamp = (
        entry.get("create_time")
        or entry.get("createTime")
        or entry.get("timestamp")
        or entry.get("created_at")
    )
    if not timestamp:
        return None
    
    if isinstance(timestamp, str):
        timestamp_dt = from_iso_format(timestamp)
    else:
        return None
    
    speaker_name = entry.get("sender_name") or entry.get("sender")
    if not speaker_name:
        origin = entry.get("origin")
        if isinstance(origin, dict):
            speaker_name = origin.get("fullName") or origin.get("full_name")
    if not speaker_name:
        return None
    
    speaker_id = None
    origin = entry.get("origin")
    if isinstance(origin, dict):
        speaker_id = origin.get("createBy") or origin.get("create_by")
    if not speaker_id:
        speaker_id = entry.get("sender_id") or entry.get("sender")
    
    content = str(entry.get("content", ""))
    
    return {
        "speaker_id": str(speaker_id or speaker_name),
        "speaker_name": str(speaker_name),
        "content": content,
        "timestamp": timestamp_dt,
    }


async def extract_memories():
    """ä½¿ç”¨ V3 API æ–¹å¼æå–è®°å¿†"""
    print("\n" + "=" * 80)
    print("ä½¿ç”¨ V3 API æå–è®°å¿†")
    print("=" * 80)
    
    # åŠ è½½æ•°æ®
    print(f"\nâœ“ åŠ è½½èŠå¤©æ•°æ®: {DATA_FILE.name}")
    events = load_chat_data(DATA_FILE)
    print(f"  - å…± {len(events)} æ¡æ¶ˆæ¯")
    
    # åˆå§‹åŒ– MemoryManager
    manager = MemoryManager()
    
    # é€æ¡å¤„ç†æ¶ˆæ¯
    history: List[RawData] = []
    saved_count = 0
    
    print("\nâœ“ å¼€å§‹å¤„ç†æ¶ˆæ¯...")
    
    for idx, entry in enumerate(events):
        # å½’ä¸€åŒ–
        message_payload = normalize_message(entry)
        if not message_payload:
            continue
        
        message_id = (
            entry.get("message_id")
            or entry.get("id")
            or entry.get("uuid")
            or f"msg_{idx}"
        )
        
        raw_item = RawData(
            content=message_payload,
            data_id=str(message_id),
            data_type=RawDataType.CONVERSATION,
        )
        
        # åˆå§‹åŒ–
        if not history:
            history.append(raw_item)
            continue
        
        # æ„å»ºè¯·æ±‚
        request = MemorizeRequest(
            history_raw_data_list=list(history),
            new_raw_data_list=[raw_item],
            raw_data_type=RawDataType.CONVERSATION,
            user_id_list=["default"],
            group_id="assistant",
            enable_semantic_extraction=True,   # âœ… å¯ç”¨è¯­ä¹‰è®°å¿†
            enable_event_log_extraction=True,  # âœ… å¯ç”¨ Event Log
        )
        
        # è°ƒç”¨ memorize
        result = await manager.memorize(request)
        
        if result:
            saved_count += 1
            print(f"  [{saved_count}] âœ… æå–æˆåŠŸï¼Œè¿”å› {len(result)} ä¸ª Memory")
            
            # é‡ç½®å†å²
            history = [raw_item]
        else:
            # ç»§ç»­ç´¯ç§¯
            history.append(raw_item)
            if len(history) > 20:
                history = history[-20:]
    
    print(f"\nâœ… å¤„ç†å®Œæˆï¼Œå…±æå– {saved_count} ä¸ª MemCell")
    return saved_count


async def verify_results(expected_count: int):
    """éªŒè¯å­˜å‚¨ç»“æœ"""
    print("\n" + "=" * 80)
    print("éªŒè¯å­˜å‚¨ç»“æœ")
    print("=" * 80)
    
    # 1. éªŒè¯ MongoDB
    print("\n[MongoDB] æ£€æŸ¥ MemCell")
    memcell_repo = get_bean_by_type(MemCellRawRepository)
    memcells = await memcell_repo.find_by_group_id("assistant", limit=100)
    print(f"  - æ‰¾åˆ° {len(memcells)} ä¸ª MemCell")
    
    if memcells:
        # ç»Ÿè®¡å†…å®¹
        total_semantic = 0
        total_eventlog = 0
        
        for memcell in memcells:
            if hasattr(memcell, 'semantic_memories') and memcell.semantic_memories:
                total_semantic += len(memcell.semantic_memories)
            if hasattr(memcell, 'event_log') and memcell.event_log:
                event_log = memcell.event_log
                if isinstance(event_log, dict):
                    total_eventlog += len(event_log.get('atomic_fact', []))
                else:
                    total_eventlog += len(getattr(event_log, 'atomic_fact', []))
        
        print(f"  - episode: {len(memcells)} ä¸ª")
        print(f"  - semantic_memories: {total_semantic} ä¸ª")
        print(f"  - event_log atomic_facts: {total_eventlog} ä¸ª")
        print(f"  - é¢„æœŸ Milvus/ES è®°å½•æ•°: {len(memcells) + total_semantic + total_eventlog}")
    
    # 2. éªŒè¯ Milvus
    print("\n[Milvus] æ£€æŸ¥è®°å½•")
    milvus_repo = get_bean_by_type(EpisodicMemoryMilvusRepository)
    
    # æŸ¥è¯¢æ‰€æœ‰è®°å½•ï¼ˆç”¨ä¸€ä¸ªé€šç”¨å‘é‡ï¼‰
    from agentic_layer.vectorize_service import get_vectorize_service
    vectorize_service = get_vectorize_service()
    query_vector = await vectorize_service.get_embedding("æµ‹è¯•")
    
    milvus_results = await milvus_repo.vector_search(
        query_vector=query_vector,
        user_id="default",
        limit=1000,
    )
    print(f"  - æ‰¾åˆ° {len(milvus_results)} æ¡è®°å½•")
    
    # ç»Ÿè®¡ç±»å‹åˆ†å¸ƒ
    from collections import Counter
    if milvus_results:
        types = [r.get('memory_sub_type', 'unknown') for r in milvus_results]
        type_counts = Counter(types)
        print(f"  - ç±»å‹åˆ†å¸ƒ: {dict(type_counts)}")
    
    # 3. éªŒè¯ ES
    print("\n[ES] æ£€æŸ¥è®°å½•")
    es_repo = get_bean_by_type(EpisodicMemoryEsRepository)
    
    # æŸ¥è¯¢æ‰€æœ‰è®°å½•
    es_results = await es_repo.multi_search(
        query=[],
        user_id="default",
        size=1000,
    )
    print(f"  - æ‰¾åˆ° {len(es_results)} æ¡è®°å½•")
    
    # ç»Ÿè®¡ç±»å‹åˆ†å¸ƒ
    if es_results:
        types = [r.get('_source', {}).get('type', 'unknown') for r in es_results]
        type_counts = Counter(types)
        print(f"  - ç±»å‹åˆ†å¸ƒ: {dict(type_counts)}")
    
    # 4. æµ‹è¯• ES æ£€ç´¢
    print("\n[ES] æµ‹è¯•å…³é”®è¯æ£€ç´¢")
    search_results = await es_repo.multi_search(
        query=["åŒ—äº¬", "æ—…æ¸¸"],
        user_id="default",
        size=10,
    )
    print(f"  - æŸ¥è¯¢'åŒ—äº¬ æ—…æ¸¸': æ‰¾åˆ° {len(search_results)} æ¡")
    
    if search_results:
        print(f"  - ç¬¬ä¸€æ¡ç»“æœ:")
        first = search_results[0]['_source']
        print(f"    type: {first.get('type')}")
        print(f"    episode: {first.get('episode', '')[:100]}...")
    
    # 5. ç»“æœæ±‡æ€»
    print("\n" + "=" * 80)
    print("æµ‹è¯•ç»“æœæ±‡æ€»")
    print("=" * 80)
    print(f"\nâœ… MongoDB MemCell: {len(memcells)} ä¸ª")
    print(f"âœ… Milvus è®°å½•: {len(milvus_results)} æ¡")
    print(f"âœ… ES è®°å½•: {len(es_results)} æ¡")
    print(f"âœ… ES æ£€ç´¢: {len(search_results)} æ¡ï¼ˆå…³é”®è¯'åŒ—äº¬ æ—…æ¸¸'ï¼‰")
    
    if len(milvus_results) > 0 and len(es_results) > 0 and len(search_results) > 0:
        print("\nğŸ‰ æµ‹è¯•é€šè¿‡ï¼V3 API åŠŸèƒ½æ­£å¸¸ï¼")
    else:
        print("\nâš ï¸ éƒ¨åˆ†åŠŸèƒ½å¼‚å¸¸ï¼Œè¯·æ£€æŸ¥æ—¥å¿—")


async def main():
    """ä¸»å‡½æ•°"""
    print("=" * 80)
    print("V3 API ç®€å•æµ‹è¯•ï¼ˆåŒæ¬¾ extract_memory åŠŸèƒ½ï¼‰")
    print("=" * 80)
    print(f"æ•°æ®æ–‡ä»¶: {DATA_FILE}")
    print("=" * 80)
    
    # æ­¥éª¤ 1: æ¸…ç©ºæ•°æ®
    await clear_all_data()
    
    # æ­¥éª¤ 2: æå–è®°å¿†
    count = await extract_memories()
    
    # ç­‰å¾…æ•°æ®åˆ·æ–°
    print("\nâ³ ç­‰å¾… 3 ç§’ï¼Œç¡®ä¿æ•°æ®å†™å…¥...")
    await asyncio.sleep(3)
    
    # æ­¥éª¤ 3: éªŒè¯ç»“æœ
    await verify_results(count)
    
    print("\n" + "=" * 80)
    print("æµ‹è¯•å®Œæˆ")
    print("=" * 80)


if __name__ == "__main__":
    asyncio.run(main())

